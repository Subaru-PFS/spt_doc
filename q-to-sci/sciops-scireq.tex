\documentclass[a4paper,notitlepage]{article}
\usepackage{ssn-format}
\drafttrue
\title{Items to be discussed on science requirements on PFS software}
\author{Atsushi Shimono + Naoyuki Tamura}

\newcommand{\cols}[1]{\textcolor{red}{\thesubsubsection-#1}}
\newcommand{\colm}[1]{\textcolor{yellow}{\thesubsubsection-#1}}
\newcommand{\coll}[1]{\textcolor{blue}{\thesubsubsection-#1}}

\begin{document}

\SSNID{00003}
\SSNREV{000}
\SSNCATEGORY{ALL}
\SSNChangeRecord{Rev.001 / First Release / 2013--11--16}
\SSNReference{(none)}
\SSNAttachment{(none)}
\SSNWritten{Atsushi Shimono + Naoyuki Tamura}

\ssnhead

\section{Abstract}

This document is to start discussion to collect requirements from the
science team to the PFS software packages. Especially from the survey
operation points of view, what each software component needs to do and
what kind of user interfaces are necessary are expected to be
clarified. In Section 2, current ideas and understandings of possible
styles of PFS surveys at the instrument builders' sides are presented,
and in Section 3 questions and future discussion items are listed so
that replies from the science team to them can be considered as pieces
of the requirements to the software components.

From SDSS, Michael Strauss gave us a presentation titled "SDSS survey
design \& operation: Inputs for PFS".

\section{PFS survey basics}

Some basic features of PFS surveys can be listed as follows:
\begin{itemize}
 \item PFS survey will consist of four sub-surveys having different
       features as exemplified in
       Table.~\ref{tab:sciops-scireq-subsvy}).
 \item Sub-surveys may share fields and/or exposures.
 \item More targets may exist than fiber \# per field, so each field
       may be exposed multiple times, depending on sub-surveys and
       their goals.
 \item Since a large number of fibers are available and the number of
       targets is probably even larger, processes of survey planning,
       execution, and data reduction should be automated as much as
       possible.
\end{itemize}

\begin{table}[htb]
\caption{Requirements per sub-survey (sample; not completed)}
\label{tab:sciops-scireq-subsvy}
\begin{center}
\begin{tabular}{c|c|c|c|c}
conditions & cosmology & GA-LR & GA-MR & galaxy-AGN \\ \hline
\hline
Individual exposure time & 15min & 15min & 15min & 15min \\
\hline
Total integration time per object & 15min & 120min & 180min & 180min \\
\hline
Science target density (\#/arcmin) & ? & ? & ? & ? \\
\hline
Number of sky fibers per field & ? & ? & ? & ? \\
\hline
Number of calibration stars per field & ? & ? & ? & ? \\
\hline
 : & : & : & : & : \\
\end{tabular}
\end{center}
\end{table}

\subsection{Processing a survey}

\subsubsection{Preparation}

Having master catalog(s) of target objects as inputs, fields of which
centers correspond to telescope pointings are output and fibers are then
allocated to targets in each field
(e.g. Figure.~\ref{fig:sciops-scireq-slide-svyexp}). Multiple fiber
allocations may be considered on a single field so that more targets can
be observed. {\it Some rules need to be applied in defining the fields
(i.e. field center \& position angle are chosen) and allocating fibers
to targets, in order to maximize survey observation efficiency.}  In the
fiber allocation, some key instrument features such as collisions of
neighboring fiber positioners and field distortion on the PFI focal
plane will also be taken into account.

\begin{figure}[htb]
  \begin{center}
    \includegraphics[width=.75\linewidth]{sciops-scireq-slide-svyexp.png}
  \end{center}
  \caption{Schematic view of procedure from list of catalogues to exposure 
    configurations}
  \label{fig:sciops-scireq-slide-svyexp}
\end{figure}

\subsubsection{Observation at the summit}

In Figure.~\ref{fig:sciops-scireq-slide-oneexp}, the basic instrument
operation and data flow in PFS observation is described as a
flowchart. Once the previous exposure is completed, the telescope starts
slewing to the next target field. Using the Acquisition \& Guide (A\&G)
cameras, field acquisition is performed and auto guiding is then
initiated. In parallel to these, fiber configuration is executed, and a
new exposure is started. While CCD detectors are read out only once at
the end of an exposure, IR detector is continuously read out during an
exposure (so-called up-lamp) and outputs a single FITS image at the end
making use of all the data in the intermediate readouts. The FITS data
from the CCD and IR detectors are transferred to Hilo and on-site quick
data reduction process is applied, during the next exposure (see the
). Results from this on-site quick data reduction will be transferred to
survey planning \& tracking software for records so that the operators
at the summit can check and consider them for subsequent exposures. Some
more details about the quick and full data reduction pipelines are given
in \S~\ref{datareduction}.

\begin{figure}[htb]
  \begin{center}
    \includegraphics[width=.75\linewidth]{sciops-scireq-slide-oneexp.png}
  \end{center}
  \caption{Activities during observation along timeline}
  \label{fig:sciops-scireq-slide-oneexp}
\end{figure}

%\paragraph{Updating exposure configuration to fit with condition}
%
%Actual observation PA will be defined at the Summit just before each
%exposure, since rotation angle of PFI from the center need to be
%restricted within $\pm$ 60 degree ([TBC]) to make fiber FRD small as
%possible.  We have rotation symmetry by 60 degree on focal plane
%including fiber positioner and A\&G camera, we can rotate PFI by 60
%degree to get the same exposure configuration (excluding individual
%difference among each fiber).  To adjust PA of PFI by rotating integral
%multiplication of 60 degree, we need to update fiber configuration and
%object positions of A\&G and AG with using final settings of PA, to meet
%with small shift per each fiber positioner.  Also ETS need to consider
%of these possible error areas for collision detection among positioners
%during fiber configuration trial.

\subsubsection{Data reduction}
\label{datareduction}

PFS will have two modes of data reduction pipeline (DRP): on-site
quick-look mode, and off-site full mode. The former, which will be
applied to data ``on the fly'' i.e. as they come out in the middle of a
night, will likely be a simplified version of the off-site full DRP. The
full mode will have two functions. One is to reduce a set of data after
each night or each run of a few to several nights to integrate them into
those from the already executed part of the survey. The other is to
periodically do a systematic batch analysis of all the data that have
been already taken.
% But pipeline will be the same for two modes (TBC).

PFS data reduction will be processed roughly as follows (see also
Figure.~\ref{fig:sciops-scireq-drp-slide}): 

\begin{itemize}
  \item 2D extraction of fibers to 1D spectra
  \item Calibration and sky (continuum) subtraction (note: for bright sky 
    emission lines, currently not sure for detail, e.g. 2D PSF deconvolution)
  \item Combine multiple exposures into one spectrum and measure scientific 
    values
\end{itemize}

Details will be described elsewhere by the DRP development team (some
already exist in the PDR techincal document and presentations in the PDR
and other collaboration meetings).

%Current assumpsions are 
%\begin{itemize}
% \item Host at Hilo, transfer data in parallel or right after submitted%
%    to Gen2
%       \begin{itemize}
%    \item IR (up-ramp) : just transfer finalized image not raw
%          up-ramp, right after end of exposure and image
%          finalization
%    \item other : transfer data right after end of readout
%      \end{itemize}
% \item Calibrate with pre-built data, but not with simultaneous 2D/1D 
%       calibration data (including PSF/FRD)
% \item Process during next exposure, and return data quality metrics (well?) 
%       before beginning of next configuration
% \begin{itemize}
%  \item How we can reduce pipelines will be a trade off between quality 
%        and time of data processing
% \end{itemize}
%\end{itemize}

\subsubsection{Quality assurance (QA) and survey progress tracking}

%PFS will have an on-site quick data reduction pipeline (DRP) as a simple
%version of the off-site full DRP.
So far we assume that after each single exposure, the quick DRP is
applied and some QA process is performed, but {\it QA process has not
been specifically defined yet.}  One example that will likely be
implemented is the measurement of signal-to-noise ratios (S/N) of
spectra of science and calibration targets, but if others are needed,
they should be requested, although what information can be extracted
with good enough accuracy from a single exposure is somewhat unclear at
this moment. Based on the results from on-site quick DRP, observation
strategy may be updated during a run (or even during a night, if
required), but the information that can be obtained is limited by the
capability of quick DRP. Clearly trade studies will be needed by
comparing required information with computational power (processing
time). \footnote{With making computing resources larger, we might be
possible shorten processing time without reducing procedure in some
level..}.

As survey observation progresses, more data are integrated and the
quality of spectra is improved. The quick and full DRPs will send the
information of the quality of existing spectra on a individal object
basis to survey planning and tracking software (SPT). {\it Some criteria
need to be defined judge whether or not enough data have been taken for
single fields and/or individual objects.} Once a single object and/or
field is considered ``done'', subsequent observation strategy
(e.g. field definition, fiber configuration, required number of
exposures, etc) is expected to be updated by SPT.

\begin{figure}[htb]
  \begin{center}
    \includegraphics[width=.75\linewidth]{sciops-scireq-drp-slide.png}
  \end{center}
  \caption{Schematic process for PFS data reduction pipeline}
  \label{fig:sciops-scireq-drp-slide}
\end{figure}

\subsection{PFS Software lineup}

To perform all required activities on PFS, PFS software is defined as
four packages and executes a survey as
Figure.~\ref{fig:sciops-scireq-slide-softcoord}:
\begin{description}
 \item[ICS] Instrument Control Software\footnote{So-called ``OBCP'' in
        the Subaru's terminology is a key role of ICS.}
        \begin{itemize}
         \item Everything from observation operation (provided exposure
           configuration) to output raw data.
         \item Including control software directly connected to hardware
         \item Including software for engineering, heartbeat, etc.
        \end{itemize}
 \item[DRP] Data Reduction Pipeline
        \begin{itemize}
         \item Reducing and calibrating raw data for science
         \item On-site quick look DRP, reduced data archive
        \end{itemize}
 \item[ETS] Exposure Targeting Software
        \begin{itemize}
         \item From possible target lists in a single field to fiber
           configuration for a single exposure
         \item Handling coordinate transformation related on sky coordinate
           (within one field)
        \end{itemize}
 \item[SPT] Survey Planning and Tracking software
        \begin{itemize}
         \item From large survey target lists to series of exposures on
           multiple fields
         \item Tracking survey progress including data QA for every
           exposure (by off-site full-DRP)
        \end{itemize}
\end{description}

\begin{figure}[htb]
  \begin{center}
    \includegraphics[width=.75\linewidth]{sciops-scireq-slide-softcoord.png}
  \end{center}
  \caption{Sequence of top level activities for entire survey and 
    their associated package}
  \label{fig:sciops-scireq-slide-softcoord}
\end{figure}

From data point of view, each package will handle data or table as
color-coded in Figure.~\ref{fig:sciops-scireq-slide-data}. Supplied
objects by catalogues from science team will be mapped into exposure
field lists. For each exposure field list, multiple exposure
configuration will be created, and results or intermediate outputs will
be attached to each configuration and each field list.  For each
exposure configuration, exposed data and reduced results will be
attached after execution of exposure.

\begin{figure}[htb]
  \begin{center}
    \includegraphics[width=.75\linewidth]{sciops-scireq-slide-data.png}
  \end{center}
  \caption{Relationship between supplied and exposed data from catalogue
    to survey tracking data} \label{fig:sciops-scireq-slide-data}
\end{figure}

\section{Questions and Discussion items}

In this section, a list of questions to the science team and future
discussion items are presented, in order to collect requirements needed
to develope the listed software packages.

The priorities \& types of questions/discussion items are color-coded as
follows:
\begin{enumerate}
  \item[\colm{a}] High priority. Replies are requested in a short time
           scale, like 1 month.
  \item[\cols{b}] Less urgent, so please send replies in 6 months.
  \item[c] Others
\end{enumerate}

{\bf Important notes:}
\begin{itemize}
 \item Replies do NOT need to be based on solid plans of your
   surveys. Please tell us current ideas, which should be a good
   starting point of discussion.
 \item Honestly speaking, there may be some important questions and
       discussion items that are missed from this document, so comments
       and additions are welcome.
 \item The format of some questions may not be ideal and therefore may
       not allow you to answer them easily. In such a case, please send
       us your comments and point out why you feel it difficult to
       reply. For example:
       \begin{itemize}
    \item Question is not well understood.
    \item Question is not applicable to my survey.
    \item My survey has different types of requirements such as ... 
    \item ... etc
       \end{itemize}
 \item The questions presetend in this document are the first
   set. Your replies to them will then allow us to send you more
   advanced questins. There are a number of subjects which need to be
   iteratively discussed for us to correctly understand requirements
   for relevant implementations.
\end{itemize}

\subsection{Survey basics}

\begin{enumerate}
  \item[\colm{a}] Complete Table~\ref{tab:sciops-scireq-subsvy} by
           checking the numbers that already exist, and giving
           typical numbers to the slots currently occupied by
           ``?''. If ANY corrections and/or additions are necesary,
           please send them to us.
\end{enumerate}

\subsection{Survey preparation}

\subsubsection{Target list}

\begin{enumerate}
 \item[\colm{a}] How would you prepare master catalog(s)?  Please
          include some explanations of your ideas about the key
          issues as listed below:
          \begin{itemize}
           \item Original data or catalog(s) based on which master
             catalog(s) for PFS survey are created
           \item Types of objects to be included. Presumably all
             potential targets not only for science but also for
             calibration, field acquisition, and auto guiding
             (i.e. stars) are included?
           \item Catalog format (number of columns, parameters to be
             listed, etc)
           \item Astrometry (reference star catalog, etc)
          \end{itemize}
\end{enumerate}

\subsubsection{Field definition}

\begin{enumerate}
 \item[\colm{a}] How do you want to determine field centers and position
          angles of the fields? Are there any possible optimization
          processes in your mind? Possible examples may be:
          \begin{itemize}
           \item Maximizing the accessibility to high-priority
             science targets
           \item Maximizing the number of stars that can be imaged
             by the A\&G cameras for field acquisition and auto
             guiding.
           \item Uniformizing the number of science targets per
             field.
          \end{itemize}
 \item[\colm{a}] Do you need to visit individual fields multiple times?
          If yes:
          \begin{itemize}
           \item How would you define the number of visits?
           \item Would you keep the field center and position angle
             for all the visits?
          \end{itemize}
 \item[\colm{a}] Do you need to have an overlap between neighboring
          fields? If yes, how would you want to define such an
          overlap?
\end{enumerate}

\subsubsection{Fiber allocation}

For each field (or each exposure), a list of objects need to be selected
from the master catalog(s) and fibers are assigned to them for
integration. In addition to science targets, fibers will need to be
allocated to calibration stars and blank sky areas. In some cases, you
may also want to mix science targets for other sub-surveys into your
fiber allocation.

\begin{enumerate}
  \item[\coll{a}] Based on what kind of criteria/rules/procedures would
           you like to select science targets to which fibers are
           allocated? Some possible examples are:
           \begin{itemize}
        \item A merit function that is defined by a subset of
              parameters in the master catalog.
        \item Priority that is given in advance to individual
              objects or categories of them in the master
              catalog.
           \end{itemize}
  \item[\coll{a}] If you need to visit single fields multiple times, how
           would you want to split objects into subsets for the
           multiple visits and determine fiber allocations?
  \item[\coll{b}] How do you want to split fibers into the targets for
           your survey and those for other PFS sub-surveys, if
           required?
%   \begin{itemize}
%     \item When one field or exposure is shared by multiple surveys, we need 
%       to combine two indexes supplied by each survey.
%     \item How to do? Integrate into single merit function, or threshold like 
%       "Survey A index 1 need to be observed up to 80\%", etc.
%    \end{itemize}
  \item[\coll{b}] What type of objects (stars) would you select as
           calibration stars? How many of them will be enough for
           your goals of calibration (See
           Table.~\ref{tab:sciops-scireq-subsvy}), accounting for
           e.g. possibility of cross-check? Any specific
           requirements to their spatial distribution in the field?
  \item[\coll{b}] How would you define ``blank'' sky areas for sky
           fibers? Do you think you can define ``blank'' sky areas
           just based on the information in your master catalog(s)?
  \item[\coll{b}] How do you want to spatially distribute the sky fibers
           in one field?
\end{enumerate}

%\paragraph{Miscellaneous targets}
%
%Definitions of criteria or requirements for miscellaneous targets will 
%vary per each survey, and we need to have a table like 
%Table.~\ref{tab:sciops-scireq-subsvy}. 
%
%\begin{enumerate}
%  \item[a] How many fibers need to be assigned to these targets, including 
%    distribution over a field? 
%  \item[b] Sky fiber positions checked using HSC image or other scheme?
%  \item[c] Calibration star selection criteria: color? intensity? instrument deformation?
%\end{enumerate}

\subsection{Observation execution}

\begin{enumerate}
  \item[\coll{a}] Will you possibly want to visit a certain field
           multiple times in different nights/runs/seasons when it
           is technically feasible?\footnote{Depending on when you
           observe a given area of sky, the positions of target
           objects on the focal plane slightly change due to
           e.g. differential atmospheric refraction, so fiber
           positions need to be adjusted accordingly. The operation
           of the rotator will also be different again depending on
           observing time, due to the $+/-60^{\circ}$ limitation
           (for the sake of minimizing Focal Ratio Degradation (FRD)
           variation, exploiting the hexagonal symmetry of the focal
           plane).}
  \item[\coll{a}] As mentioned in the other parts of this document, we
           expect some QA process is performed and based on the
           information from it observation strategy (e.g. field
           definition, fiber configuration, required number of
           exposures, etc) may be updated. How often would you
           likely want to apply such updates? Between exposures?
           Between nights?
%  \item[\colm{b}] Some survey requires software to stop exposure after certain 
%    signal to noise ratio achieved. 
%    If we expose the same field with the same fiber configuration
%    continuously, we cannot stop by the next exposure after achieval. 
%    How do we do -- prevent such continuous exposure (change every objects 
%    at any time), take survey time efficiency by ignoring such small number of 
%    targets.
\end{enumerate}

%\paragraph{If we dither, rotate or overlap fields}
%
%If field definition is static and almost without gap nor overrap, 
%one target will be mapped into one fiber positioner, and we don't need to 
%care of complex multiple -- multiple assignments. 
%But if not, we might need to care of many things... 
%
%\begin{enumerate}
%  \item[\cols{a}] How many targets we can assume per one fiber positioner patrol 
%    area?
%  \item[b] If we have multiple targets within one fiber positioner patrol 
%    area, set of targets per patrol area will differ field by field 
%    (e.g. target A and B are in area 1 for configuration x, 
%    A in 100 and B in 101 for configuration y). 
%    Survey progress will be complexed and it will take more exposurs to 
%    complete "minimum set", is it ok?
%  \item[c] Do we need to optimize exposure configurations and fiber -- target 
%    assignments over entire survey period or just a exposure by a exposure? 
%\end{enumerate}

\subsection{Data reduction}

%This section covers requirements about data reduction pipeline from raw
%data to reduced 1D spectrum and scientific values extracted from
%spectrum \footnote{Check later section for reduced data and scientific
%values' archive.}. Science requirements including reduction and
%calibration accuracies shall be discussed in separated for two modes.

%\subsubsection{On-site quick DRP}

%\subsubsection{off-site full data reduction pipeline}

%For functional requirements, final output from data reduction pipeline
%will be survey archive data, such as table of astrophysical values,
%reduced data sets (1D spectra and required intermediate outputs). 

%On this point, we need to define what information or output are required
%to be produced:

\begin{enumerate}
 \item[a] After a fully reduced and calibrated 1D spectrum is extracted,
      what do you want to measure using the spectral features?
 \item[a] Could you briefly explain how you will measure them?
      For example:
      \begin{itemize}
       \item Measure a redshift (or radial velocity) by fitting a
         gaussian to an emission/absorption line (more than one
         lines are fitted simultaneously if available).
      \end{itemize}
 \item[a] Do you think there are any special recipes of data reduction
      and calibration that are needed to the data for your
      (sub-)surveys but are not needed for other surveys?
%          たぶん、GA のデータにせよ cosmology のデータにせよ同じようにリ
%      ダクションをしてキャリブレーションをするのが現在のベースライン
%      ではないのか。それでいいのか、サブサーベイごとに何かスペシャル
%      なプロセスが必要ということはないのか、という点に関する質問。質
%      問すべきかそうでないか確信なし。また、現在の質問フォーマットは
%      非常に答えにくい(全部知っている Jim みたいな人じゃないと答えら
%      れない)。改良できる？
 \item[b] The data reduction and calibration follow many steps, so a
      number of intermediate data will be formed. Are there anything
      specific among them you will likely need/want to access to?
%      例を挙げる？
\end{enumerate}

\subsubsection{Data QA and feedback to SPT}

\begin{enumerate}
 \item[a] While you are integrating certain objects, to monitor the
      quality of your spectra, what kind of quantities and/or
      diagnostics would you need to see? Earlier in this document,
      S/N (of continuum and/or emission line which may depend on the
      survey objectives) is presented as an example (c.f. integrated
      S/N at SDSS). Is this appropriate? Are there any others in
      addition to S/N? Some examples may be:
      \begin{itemize}
       \item Record flux level and noise level separately.
       \item Record fiber positioning errors (residual distances
         from the target positions).
      \end{itemize}
 \item[a] Data quality also strongly depends on sky conditions and
      instrument status at individual exposures. What information
      would you specifically want to be recorded?
 \item[a] In what criteria should each object be judged ``done''
      (i.e. no more integration is needed)?
 \item[a] In what criteria should each field or each fiber configuraiton
      be judged ``done'' (i.e. no more visit is needed to this
      field/configuration)?
 \item[b] The estimation of e.g. S/N by quick DRP is perhaps less
      accurate than full DRP, so more objects may be judged ``done''
      after applying full DRP. Conversely, detailed reduction by
      full DRP may reveal some errorneous features in the data that
      are not detected by quick DRP and some objects may need to be
      ``undone''. So is it correct that you would like to see if
      updates are necessary to observation plans based on not only
      the outputs from on-site quick DRP but also off-site full DRP
      when available?
\end{enumerate}

\subsection{User interface requirements for survey coordination}

Users approach to software components in order to access to some data
and/or accomplish some tasks. Hence requirements for user Interface
should be about what data to be stored and how to visualize them.
%And requiremnts on the User Interface could be divided into two: "What
%data we need to store", and "What panel we need". At this moment,
%system design is at conceptural level and no detailed design is planned,
In this document, requirements to data types are mainly discussed, and
those for visualization will be discussed in more detail elsewhere in
future.

Below, we will present a list of questions and discussion items along
the three phases in processing a survey:
\begin{enumerate}
  \item[1] Preparation 
  \item[2] Observation execution and data reduction
  \item[3] Monitoring of survey progress
\end{enumerate}
So far we assume "observation execution" will be performed mainly by
small groups of people (c.f. night operation at Subaru is carried out by
one telescope operator, one instrument operator (usually support
scientist), and max. 4 observers). In the other two phases, many project
members will attend and interact remotely from various places.

\subsubsection{Preparation}

In this phase, given a master catalog of target objects is provided
initially, SPT will define fields and then ETS will make fiber
allocation employing some rules of selection and prioritization.

SPT will output, at least, a list of field centers and position angles
of defined fields, and object lists residing in each field. Currently we
assume the object list has the same format as the master catalog, since
a subset of the parameters therein may be used in the process of fiber
allocation by ETS.

\begin{enumerate}
  \item[a] Would you want to receive the data output by SPT in some
    specific format? Or, as long as a visualization tool is prepared
    to show the defined fields etc, any format would be acceptable?
  \item[a] Are there any other outputs expected from SPT? (e.g. a log
    file recording some details of how fields are defined)
  \item[b] What input to and output from ETS shall be stored?
    \begin{itemize}
      \item Decision tables? Results from merit function? Or any other 
        intermediate products or decision data?
      \item Pre-input data used within SPT? - relates what algorithm we will use.
      \item To ETS, all output from ETS will be saved by SPT, what ETS need 
        to output? (section before)
    \end{itemize}
  \item[c] How we do for history of planning?
    \begin{enumerate}
      \item[c1] We need at least to save snapshots?
      \item[c2] How do we deal with version of catalog itself? Like using master 
        object ID, among all supplied object catalogue?
    \end{enumerate}
\end{enumerate}

\subsubsection{Survey operation \& data reduction}

Per night operation will be similar to classical typed observation (by
means of checking possible target fields (all, next), and statistics
from exposed frames (or on-site DRP) will be used for operation.

\paragraph{For operation}

\begin{enumerate}
  \item[a] What information shall be presented to operator to understand and 
    decide what operator need to and can do per night (or for next exposure)?
  \item[b] How level do we need to operate survey observation automatically?
    As for now, assuming somehow similar to classical typed observation..
\end{enumerate}

\paragraph{Recording telemetry and status}

\begin{enumerate}
  \item[a] What status and telemetry shall be transferred from ICS to SPT 
    related with exposure.
  \item[b] What statistics from on-site (quick) DR shall be recorded, all?
\end{enumerate}

\subsubsection{Monitoring of survey progress - ideas}

This covers checking progress status per survey, per field, per object: 
time, S/N etc. Could be one additional layer to survey archive??

\begin{enumerate}
  \item[a] What statistics need to be archived from off-site full-suite DR?
    \begin{itemize}
      \item per frame, per spectra, per field, per object
      \item into FITS header of processed image or survey record database?
    \end{itemize}
  \item[b] STP need to keep information in hierarchical to be displayed as layered UI.
  \item[c] How about progress history? -- we will integrate exposures per object
  \item[d] Searchable table : this will be UI design, but capable to be searchable 
    by many indexes??
\end{enumerate}

\subsubsection{Interface to ICS}

Many information required by SPT will be generated by other packages, we need 
to define what we need to keep for survey planning and tracking, and to 
allocate these requirements to other packages. 

Based on design concept of "keeping all information as much as possible", 
ICS will keep all telemetry (interval TBD) and logs (e.g. command, status), 
to use for defect detection and instrument performance check on the 
instrument control (e.g. performance of COBRA, A\&G/AG star).
On interface between SPT and ICS, what is required for SPT? Such as, instrument 
performance (e.g. fiber positioning error, A\&G/AG performance), instrument 
error report. Of course, we could get all archived data from ICS to SPT. 

\subsection{For survey archive}

Survey archive requirement and design is not well developed.

\begin{itemize}
  \item SDSS DR web as a starting point for a set of requiremnt?
  \item Automatic release of status/progress report per night or per run
    (As Gen2 of Subaru is doing: release PDF after each night)
  \item Visualization via kml? 
    (<kml xmlns="http://www.opengis.net/kml/2.2" hint="target=sky">)
\end{itemize}

Also, sample from LAM is attached to this document in separated. 

\subsection{For continuous data release}

As a background of survey archive, we need to perform continuous data 
reduction and periodic re-reduction of full data set.
Single(?) data reduction after each observation (single day or single run) 
could be performed on-premise (or even using on-site DR facility at Hilo 
supplied by us, although we need to care about already exposed data set...). 
And this will not be an issue.
For continuous data release like a "DR" of SDSS, Robert Lupton suggested to 
go cloud. Total "raw" data set will be around 0.5PB (to 1PB), and even after 
reduction it will be a level of 1PB including intermediate data.
It could be possible.

\begin{itemize}
  \item Do we need such periodical data release?
  \item What do we change on each data release --- pipeline upgrade?
\end{itemize}


\subsection{Other requirements for calibration}

Any requirements on calibrations?

\begin{itemize}
  \item Statistics of calibration? --- to check stability in short and long 
    term
  \item Cross-check by calibrating calibration object by themselves within a 
    frame
\end{itemize}

\section*{Appendix: System-level requirements associated with data reduction}

Currently, several statistical requirements are already included into
PFS L2 requirements:
\begin{itemize}
  \item REQ-SYS-679, sky subtraction to the accuracy of 0.5\% [TBC] or better 
    of sky
  \item REQ-SYS-896 (890), subtract diffuse background to [TBD] e- accuracy
  \item REQ-SYS-688, flat-field systematics in fibers and detectors to 0.5\% 
    [TBC] or better
  \item REQ-SYS-696, wavelength to 0.01 pixel [TBC] accuracy
  \item REQ-SYS-656, relative flax of individual object spectrum to 5\% [TBC]
    accuracy
\end{itemize}

\end{document}

